{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hljAXkvzC5Y",
        "outputId": "a080064b-5107-48a5-9cbb-087129ef9203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full bank-grade dataset generated\n",
            "   customer_id    month customer_segment region_tier product_type  \\\n",
            "0  CUST0000000  2024-01         salaried      tier_3  credit_card   \n",
            "1  CUST0000000  2024-02         salaried      tier_3  credit_card   \n",
            "2  CUST0000000  2024-03         salaried      tier_3  credit_card   \n",
            "3  CUST0000000  2024-04         salaried      tier_3  credit_card   \n",
            "4  CUST0000000  2024-05         salaried      tier_3  credit_card   \n",
            "5  CUST0000000  2024-06         salaried      tier_3  credit_card   \n",
            "6  CUST0000001  2024-01         salaried      tier_1  credit_card   \n",
            "7  CUST0000001  2024-02         salaried      tier_1  credit_card   \n",
            "8  CUST0000001  2024-03         salaried      tier_1  credit_card   \n",
            "9  CUST0000001  2024-04         salaried      tier_1  credit_card   \n",
            "\n",
            "   active_products_count  credit_card_utilization  total_monthly_obligation  \\\n",
            "0                      2                 0.652587              54470.559453   \n",
            "1                      2                 0.652587              54470.559453   \n",
            "2                      2                 0.652587              54470.559453   \n",
            "3                      2                 0.652587              54470.559453   \n",
            "4                      2                 0.652587              54470.559453   \n",
            "5                      2                 0.652587              54470.559453   \n",
            "6                      1                 0.514368              25741.183454   \n",
            "7                      1                 0.514368              25741.183454   \n",
            "8                      1                 0.514368              25741.183454   \n",
            "9                      1                 0.514368              25741.183454   \n",
            "\n",
            "   emi_amount  days_to_emi  emi_to_income_ratio  salary_delay_days  \\\n",
            "0       50220           17             0.385513                  4   \n",
            "1       50220           21             0.385513                  0   \n",
            "2       50220           10             0.385513                  2   \n",
            "3       50220           24             0.385513                  4   \n",
            "4       50220           14             0.385513                  2   \n",
            "5       50220           19             0.385513                  6   \n",
            "6       22859           22             0.203976                 29   \n",
            "7       22859           23             0.203976                 29   \n",
            "8       22859           23             0.203976                 22   \n",
            "9       22859           19             0.203976                 23   \n",
            "\n",
            "   weekly_balance_change_pct  atm_withdrawal_amount  monthly_income  \\\n",
            "0                  -9.691233           26059.642678          130268   \n",
            "1                   5.027260           13856.941078          130268   \n",
            "2                   4.954088           21234.088957          130268   \n",
            "3                  -4.263070           26882.630949          130268   \n",
            "4                  -9.024226           42350.844245          130268   \n",
            "5                  -6.536593           35092.682621          130268   \n",
            "6                 -18.942881           69168.754498          112067   \n",
            "7                 -16.953144          104683.710831          112067   \n",
            "8                 -18.886654           97373.856907          112067   \n",
            "9                 -32.976637           73554.363979          112067   \n",
            "\n",
            "   risk_level_latent  loan_default_observed  \n",
            "0                  1                      0  \n",
            "1                  0                      0  \n",
            "2                  0                      1  \n",
            "3                  1                      1  \n",
            "4                  1                      0  \n",
            "5                  1                      0  \n",
            "6                  3                      0  \n",
            "7                  3                      1  \n",
            "8                  3                      1  \n",
            "9                  3                      1  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "NUM_CUSTOMERS = 15000\n",
        "MONTHS_PER_CUSTOMER = 6\n",
        "\n",
        "customers = [f\"CUST{str(i).zfill(7)}\" for i in range(NUM_CUSTOMERS)]\n",
        "months = pd.date_range(\"2024-01-01\", periods=MONTHS_PER_CUSTOMER, freq=\"MS\")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for cust in customers:\n",
        "\n",
        "    # FAIRNESS-SAFE CUSTOMER ATTRS\n",
        "    customer_segment = np.random.choice(\n",
        "        [\"salaried\", \"self_employed\"], p=[0.7, 0.3]\n",
        "    )\n",
        "\n",
        "    region_tier = np.random.choice(\n",
        "        [\"tier_1\", \"tier_2\", \"tier_3\"], p=[0.4, 0.35, 0.25]\n",
        "    )\n",
        "\n",
        "    # Latent risk\n",
        "    risk = np.random.choice([0, 1, 2, 3], p=[0.5, 0.25, 0.15, 0.10])\n",
        "\n",
        "    monthly_income = np.random.randint(20000, 150000)\n",
        "\n",
        "    # MULTI-PRODUCT PROFILE\n",
        "    active_products_count = np.random.choice([1, 2, 3], p=[0.45, 0.4, 0.15])\n",
        "    product_type = np.random.choice(\n",
        "        [\"personal_loan\", \"credit_card\", \"bnpl\"]\n",
        "    )\n",
        "\n",
        "    emi_day = np.random.choice([5, 10, 15])\n",
        "    emi_amount = np.random.randint(\n",
        "        int(0.1 * monthly_income),\n",
        "        int(0.4 * monthly_income)\n",
        "    )\n",
        "\n",
        "    credit_card_utilization = (\n",
        "        np.random.uniform(0.2, 0.6) if product_type != \"credit_card\"\n",
        "        else np.random.uniform(0.4, 0.95)\n",
        "    )\n",
        "\n",
        "    total_monthly_obligation = (\n",
        "        emi_amount +\n",
        "        credit_card_utilization * monthly_income * 0.05\n",
        "    )\n",
        "\n",
        "    for month_start in months:\n",
        "\n",
        "        # Risk drift\n",
        "        risk += np.random.choice([-1, 0, 1], p=[0.15, 0.6, 0.25])\n",
        "        risk = np.clip(risk, 0, 3)\n",
        "\n",
        "        # EMI timing\n",
        "        emi_due_date = month_start + pd.Timedelta(days=emi_day - 1)\n",
        "        observation_date = emi_due_date - pd.Timedelta(days=np.random.randint(10, 25))\n",
        "        days_to_emi = (emi_due_date - observation_date).days\n",
        "\n",
        "\n",
        "        # STRESS SIGNALS\n",
        "        salary_delay_days = np.random.randint([0,2,7,15][risk], [3,7,15,30][risk])\n",
        "\n",
        "        weekly_balance_change_pct = np.random.uniform(\n",
        "            [-3,-10,-25,-40][risk],\n",
        "            [10,5,-5,-15][risk]\n",
        "        )\n",
        "\n",
        "        atm_withdrawal_amount = np.random.randint(\n",
        "            [5000,15000,25000,40000][risk],\n",
        "            [20000,30000,45000,70000][risk]\n",
        "        ) * (1 + credit_card_utilization)\n",
        "\n",
        "\n",
        "        # DEFAULT PROBABILITY\n",
        "\n",
        "        base_default_prob = [0.03, 0.08, 0.22, 0.45][risk]\n",
        "\n",
        "        pressure_multiplier = (\n",
        "            1\n",
        "            + 1.5 * (total_monthly_obligation / monthly_income)\n",
        "            + 0.02 * salary_delay_days\n",
        "            - 0.01 * max(weekly_balance_change_pct, 0)\n",
        "        )\n",
        "\n",
        "        default_prob = min(base_default_prob * pressure_multiplier, 0.95)\n",
        "\n",
        "        # FAIRNESS CONSTRAINT\n",
        "        if customer_segment == \"self_employed\":\n",
        "            default_prob *= 1.05\n",
        "        if region_tier == \"tier_3\":\n",
        "            default_prob *= 1.05\n",
        "\n",
        "        default_prob = min(default_prob, 0.95)\n",
        "\n",
        "        observed_default = np.random.rand() < default_prob\n",
        "\n",
        "        # Noise near boundary\n",
        "        if risk in [1, 2] and np.random.rand() < 0.08:\n",
        "            observed_default = not observed_default\n",
        "\n",
        "        rows.append({\n",
        "            \"customer_id\": cust,\n",
        "            \"month\": month_start.strftime(\"%Y-%m\"),\n",
        "\n",
        "            # Fairness-safe attributes\n",
        "            \"customer_segment\": customer_segment,\n",
        "            \"region_tier\": region_tier,\n",
        "\n",
        "            # Product data\n",
        "            \"product_type\": product_type,\n",
        "            \"active_products_count\": active_products_count,\n",
        "            \"credit_card_utilization\": credit_card_utilization,\n",
        "            \"total_monthly_obligation\": total_monthly_obligation,\n",
        "\n",
        "            # EMI\n",
        "            \"emi_amount\": emi_amount,\n",
        "            \"days_to_emi\": days_to_emi,\n",
        "            \"emi_to_income_ratio\": emi_amount / monthly_income,\n",
        "\n",
        "            # Stress signals\n",
        "            \"salary_delay_days\": salary_delay_days,\n",
        "            \"weekly_balance_change_pct\": weekly_balance_change_pct,\n",
        "            \"atm_withdrawal_amount\": atm_withdrawal_amount,\n",
        "            \"monthly_income\": monthly_income,\n",
        "\n",
        "            # Latent vs observed\n",
        "            \"risk_level_latent\": risk,\n",
        "            \"loan_default_observed\": int(observed_default)\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"financial_stress_full_bank_grade_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Full bank-grade dataset generated\")\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHuNmyKn0unI",
        "outputId": "56b86ccb-2d6a-4e8b-b010-1d7d148eac5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset shape: (45000, 78)\n",
            "Risk dataset shape: (45000, 77)\n",
            "Default dataset shape: (45000, 77)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"financial_stress_full_bank_grade_dataset.csv\")\n",
        "\n",
        "\n",
        "# SORT DATA (MANDATORY)\n",
        "df = df.sort_values([\"customer_id\", \"month\"]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# DEFINE NUMERIC FEATURES\n",
        "\n",
        "NUMERIC_COLS = [\n",
        "    \"active_products_count\",\n",
        "    \"credit_card_utilization\",\n",
        "    \"total_monthly_obligation\",\n",
        "    \"emi_amount\",\n",
        "    \"days_to_emi\",\n",
        "    \"emi_to_income_ratio\",\n",
        "    \"salary_delay_days\",\n",
        "    \"weekly_balance_change_pct\",\n",
        "    \"atm_withdrawal_amount\",\n",
        "    \"monthly_income\"\n",
        "]\n",
        "\n",
        "\n",
        "# CREATE LAG FEATURES (t-1, t-2)\n",
        "\n",
        "for col in NUMERIC_COLS + [\"risk_level_latent\"]:\n",
        "    df[f\"{col}_lag1\"] = df.groupby(\"customer_id\")[col].shift(1)\n",
        "    df[f\"{col}_lag2\"] = df.groupby(\"customer_id\")[col].shift(2)\n",
        "\n",
        "\n",
        "# CREATE TREND (DELTA) FEATURES\n",
        "\n",
        "for col in NUMERIC_COLS:\n",
        "    df[f\"{col}_delta_1\"] = df[col] - df[f\"{col}_lag1\"]\n",
        "    df[f\"{col}_delta_2\"] = df[f\"{col}_lag1\"] - df[f\"{col}_lag2\"]\n",
        "\n",
        "\n",
        "# CREATE VOLATILITY FEATURES (3-MONTH STD)\n",
        "\n",
        "VOLATILITY_COLS = [\n",
        "    \"credit_card_utilization\",\n",
        "    \"weekly_balance_change_pct\",\n",
        "    \"monthly_income\"\n",
        "]\n",
        "\n",
        "for col in VOLATILITY_COLS:\n",
        "    df[f\"{col}_std_3m\"] = (\n",
        "        df.groupby(\"customer_id\")[col]\n",
        "          .rolling(window=3, min_periods=2)\n",
        "          .std()\n",
        "          .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "# EXTRA TEMPORAL FEATURES\n",
        "\n",
        "\n",
        "ROLLING_COLS = [\n",
        "    \"credit_card_utilization\",\n",
        "    \"monthly_income\",\n",
        "    \"emi_to_income_ratio\",\n",
        "    \"weekly_balance_change_pct\"\n",
        "]\n",
        "\n",
        "WINDOW = 3\n",
        "\n",
        "\n",
        "for col in ROLLING_COLS:\n",
        "\n",
        "    g = df.groupby(\"customer_id\")[col]\n",
        "\n",
        "    #  rolling mean\n",
        "    df[f\"{col}_mean_3m\"] = (\n",
        "        g.rolling(WINDOW, min_periods=2)\n",
        "         .mean()\n",
        "         .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    #  rolling max (stress spikes)\n",
        "    df[f\"{col}_max_3m\"] = (\n",
        "        g.rolling(WINDOW, min_periods=2)\n",
        "         .max()\n",
        "         .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    #  rolling slope (trend strength)\n",
        "    df[f\"{col}_slope_3m\"] = (\n",
        "        g.rolling(WINDOW, min_periods=3)\n",
        "         .apply(lambda x: np.polyfit(range(len(x)), x, 1)[0])\n",
        "         .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# CREATE PERSISTENCE FLAGS\n",
        "\n",
        "\n",
        "df[\"emi_high_persist_3m\"] = (\n",
        "    df.groupby(\"customer_id\")[\"emi_to_income_ratio\"]\n",
        "      .rolling(3, min_periods=3)\n",
        "      .apply(lambda x: (x > 0.40).sum() >= 2)\n",
        "      .reset_index(level=0, drop=True)\n",
        "      .fillna(False)\n",
        "      .astype(int)\n",
        ")\n",
        "\n",
        "df[\"salary_delay_persist_3m\"] = (\n",
        "    df.groupby(\"customer_id\")[\"salary_delay_days\"]\n",
        "      .rolling(3, min_periods=3)\n",
        "      .apply(lambda x: (x > 5).sum() >= 2)\n",
        "      .reset_index(level=0, drop=True)\n",
        "      .fillna(False)\n",
        "      .astype(int)\n",
        ")\n",
        "\n",
        "df[\"utilization_high_persist_3m\"] = (\n",
        "    df.groupby(\"customer_id\")[\"credit_card_utilization\"]\n",
        "      .rolling(3, min_periods=3)\n",
        "      .apply(lambda x: (x > 0.75).sum() >= 2)\n",
        "      .reset_index(level=0, drop=True)\n",
        "      .fillna(False)\n",
        "      .astype(int)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# CREATE NEXT-MONTH DEFAULT TARGET\n",
        "\n",
        "df[\"loan_default_next_month\"] = (\n",
        "    df.groupby(\"customer_id\")[\"loan_default_observed\"]\n",
        "      .shift(-1)\n",
        ")\n",
        "\n",
        "\n",
        "# DROP ROWS WITH INSUFFICIENT HISTORY\n",
        "\n",
        "df_final = df.dropna().reset_index(drop=True)\n",
        "\n",
        "\n",
        "# FINAL DATASETS\n",
        "\n",
        "\n",
        "# Risk monitoring dataset (current state)\n",
        "risk_dataset = df_final.drop(columns=[\"loan_default_next_month\"])\n",
        "\n",
        "# Default prediction dataset (next-month event)\n",
        "default_dataset = df_final.drop(columns=[\"loan_default_observed\"])\n",
        "\n",
        "print(\"Final dataset shape:\", df_final.shape)\n",
        "print(\"Risk dataset shape:\", risk_dataset.shape)\n",
        "print(\"Default dataset shape:\", default_dataset.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LwFcHmtCymL",
        "outputId": "add258ed-8386-4169-f90d-e0d18fb5b76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 90000 entries, 0 to 89999\n",
            "Data columns (total 78 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   customer_id                         90000 non-null  object \n",
            " 1   month                               90000 non-null  object \n",
            " 2   customer_segment                    90000 non-null  object \n",
            " 3   region_tier                         90000 non-null  object \n",
            " 4   product_type                        90000 non-null  object \n",
            " 5   active_products_count               90000 non-null  int64  \n",
            " 6   credit_card_utilization             90000 non-null  float64\n",
            " 7   total_monthly_obligation            90000 non-null  float64\n",
            " 8   emi_amount                          90000 non-null  int64  \n",
            " 9   days_to_emi                         90000 non-null  int64  \n",
            " 10  emi_to_income_ratio                 90000 non-null  float64\n",
            " 11  salary_delay_days                   90000 non-null  int64  \n",
            " 12  weekly_balance_change_pct           90000 non-null  float64\n",
            " 13  atm_withdrawal_amount               90000 non-null  float64\n",
            " 14  monthly_income                      90000 non-null  int64  \n",
            " 15  risk_level_latent                   90000 non-null  int64  \n",
            " 16  loan_default_observed               90000 non-null  int64  \n",
            " 17  active_products_count_lag1          75000 non-null  float64\n",
            " 18  active_products_count_lag2          60000 non-null  float64\n",
            " 19  credit_card_utilization_lag1        75000 non-null  float64\n",
            " 20  credit_card_utilization_lag2        60000 non-null  float64\n",
            " 21  total_monthly_obligation_lag1       75000 non-null  float64\n",
            " 22  total_monthly_obligation_lag2       60000 non-null  float64\n",
            " 23  emi_amount_lag1                     75000 non-null  float64\n",
            " 24  emi_amount_lag2                     60000 non-null  float64\n",
            " 25  days_to_emi_lag1                    75000 non-null  float64\n",
            " 26  days_to_emi_lag2                    60000 non-null  float64\n",
            " 27  emi_to_income_ratio_lag1            75000 non-null  float64\n",
            " 28  emi_to_income_ratio_lag2            60000 non-null  float64\n",
            " 29  salary_delay_days_lag1              75000 non-null  float64\n",
            " 30  salary_delay_days_lag2              60000 non-null  float64\n",
            " 31  weekly_balance_change_pct_lag1      75000 non-null  float64\n",
            " 32  weekly_balance_change_pct_lag2      60000 non-null  float64\n",
            " 33  atm_withdrawal_amount_lag1          75000 non-null  float64\n",
            " 34  atm_withdrawal_amount_lag2          60000 non-null  float64\n",
            " 35  monthly_income_lag1                 75000 non-null  float64\n",
            " 36  monthly_income_lag2                 60000 non-null  float64\n",
            " 37  risk_level_latent_lag1              75000 non-null  float64\n",
            " 38  risk_level_latent_lag2              60000 non-null  float64\n",
            " 39  active_products_count_delta_1       75000 non-null  float64\n",
            " 40  active_products_count_delta_2       60000 non-null  float64\n",
            " 41  credit_card_utilization_delta_1     75000 non-null  float64\n",
            " 42  credit_card_utilization_delta_2     60000 non-null  float64\n",
            " 43  total_monthly_obligation_delta_1    75000 non-null  float64\n",
            " 44  total_monthly_obligation_delta_2    60000 non-null  float64\n",
            " 45  emi_amount_delta_1                  75000 non-null  float64\n",
            " 46  emi_amount_delta_2                  60000 non-null  float64\n",
            " 47  days_to_emi_delta_1                 75000 non-null  float64\n",
            " 48  days_to_emi_delta_2                 60000 non-null  float64\n",
            " 49  emi_to_income_ratio_delta_1         75000 non-null  float64\n",
            " 50  emi_to_income_ratio_delta_2         60000 non-null  float64\n",
            " 51  salary_delay_days_delta_1           75000 non-null  float64\n",
            " 52  salary_delay_days_delta_2           60000 non-null  float64\n",
            " 53  weekly_balance_change_pct_delta_1   75000 non-null  float64\n",
            " 54  weekly_balance_change_pct_delta_2   60000 non-null  float64\n",
            " 55  atm_withdrawal_amount_delta_1       75000 non-null  float64\n",
            " 56  atm_withdrawal_amount_delta_2       60000 non-null  float64\n",
            " 57  monthly_income_delta_1              75000 non-null  float64\n",
            " 58  monthly_income_delta_2              60000 non-null  float64\n",
            " 59  credit_card_utilization_std_3m      75000 non-null  float64\n",
            " 60  weekly_balance_change_pct_std_3m    75000 non-null  float64\n",
            " 61  monthly_income_std_3m               75000 non-null  float64\n",
            " 62  credit_card_utilization_mean_3m     75000 non-null  float64\n",
            " 63  credit_card_utilization_max_3m      75000 non-null  float64\n",
            " 64  credit_card_utilization_slope_3m    60000 non-null  float64\n",
            " 65  monthly_income_mean_3m              75000 non-null  float64\n",
            " 66  monthly_income_max_3m               75000 non-null  float64\n",
            " 67  monthly_income_slope_3m             60000 non-null  float64\n",
            " 68  emi_to_income_ratio_mean_3m         75000 non-null  float64\n",
            " 69  emi_to_income_ratio_max_3m          75000 non-null  float64\n",
            " 70  emi_to_income_ratio_slope_3m        60000 non-null  float64\n",
            " 71  weekly_balance_change_pct_mean_3m   75000 non-null  float64\n",
            " 72  weekly_balance_change_pct_max_3m    75000 non-null  float64\n",
            " 73  weekly_balance_change_pct_slope_3m  60000 non-null  float64\n",
            " 74  emi_high_persist_3m                 90000 non-null  int64  \n",
            " 75  salary_delay_persist_3m             90000 non-null  int64  \n",
            " 76  utilization_high_persist_3m         90000 non-null  int64  \n",
            " 77  loan_default_next_month             75000 non-null  float64\n",
            "dtypes: float64(63), int64(10), object(5)\n",
            "memory usage: 53.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6zk7mKvQC0L-",
        "outputId": "5019198c-5f8d-4cea-e0d9-804b25bb2d61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loan_default_observed</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "loan_default_observed\n",
              "0    62353\n",
              "1    27647\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['loan_default_observed'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "Jb8fipyADI6j",
        "outputId": "1513c305-e3d7-495a-e5bf-3a36b57714db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29fce078-3982-4e38-8850-51994542fb57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>month</th>\n",
              "      <th>customer_segment</th>\n",
              "      <th>region_tier</th>\n",
              "      <th>product_type</th>\n",
              "      <th>active_products_count</th>\n",
              "      <th>credit_card_utilization</th>\n",
              "      <th>total_monthly_obligation</th>\n",
              "      <th>emi_amount</th>\n",
              "      <th>days_to_emi</th>\n",
              "      <th>...</th>\n",
              "      <th>emi_to_income_ratio_mean_3m</th>\n",
              "      <th>emi_to_income_ratio_max_3m</th>\n",
              "      <th>emi_to_income_ratio_slope_3m</th>\n",
              "      <th>weekly_balance_change_pct_mean_3m</th>\n",
              "      <th>weekly_balance_change_pct_max_3m</th>\n",
              "      <th>weekly_balance_change_pct_slope_3m</th>\n",
              "      <th>emi_high_persist_3m</th>\n",
              "      <th>salary_delay_persist_3m</th>\n",
              "      <th>utilization_high_persist_3m</th>\n",
              "      <th>loan_default_next_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-01</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.331986</td>\n",
              "      <td>5.027260</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-03</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>5.240349e-17</td>\n",
              "      <td>0.096705</td>\n",
              "      <td>5.027260</td>\n",
              "      <td>7.322660</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-04</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>5.240349e-17</td>\n",
              "      <td>1.906092</td>\n",
              "      <td>5.027260</td>\n",
              "      <td>-4.645165</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-05</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>5.240349e-17</td>\n",
              "      <td>-2.777736</td>\n",
              "      <td>4.954088</td>\n",
              "      <td>-6.989157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CUST0000000</td>\n",
              "      <td>2024-06</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_3</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>2</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>54470.559453</td>\n",
              "      <td>50220</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>0.385513</td>\n",
              "      <td>5.240349e-17</td>\n",
              "      <td>-6.607963</td>\n",
              "      <td>-4.263070</td>\n",
              "      <td>-1.136761</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-01</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-02</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-17.948012</td>\n",
              "      <td>-16.953144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-03</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>3.501962e-17</td>\n",
              "      <td>-18.260893</td>\n",
              "      <td>-16.953144</td>\n",
              "      <td>0.028113</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-04</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>3.501962e-17</td>\n",
              "      <td>-22.938812</td>\n",
              "      <td>-16.953144</td>\n",
              "      <td>-8.011747</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-05</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>3.501962e-17</td>\n",
              "      <td>-30.490794</td>\n",
              "      <td>-18.886654</td>\n",
              "      <td>-10.361218</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CUST0000001</td>\n",
              "      <td>2024-06</td>\n",
              "      <td>salaried</td>\n",
              "      <td>tier_1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>1</td>\n",
              "      <td>0.514368</td>\n",
              "      <td>25741.183454</td>\n",
              "      <td>22859</td>\n",
              "      <td>17</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>0.203976</td>\n",
              "      <td>3.501962e-17</td>\n",
              "      <td>-30.733064</td>\n",
              "      <td>-19.613464</td>\n",
              "      <td>6.681586</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12 rows Ã— 78 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29fce078-3982-4e38-8850-51994542fb57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29fce078-3982-4e38-8850-51994542fb57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29fce078-3982-4e38-8850-51994542fb57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    customer_id    month customer_segment region_tier product_type  \\\n",
              "0   CUST0000000  2024-01         salaried      tier_3  credit_card   \n",
              "1   CUST0000000  2024-02         salaried      tier_3  credit_card   \n",
              "2   CUST0000000  2024-03         salaried      tier_3  credit_card   \n",
              "3   CUST0000000  2024-04         salaried      tier_3  credit_card   \n",
              "4   CUST0000000  2024-05         salaried      tier_3  credit_card   \n",
              "5   CUST0000000  2024-06         salaried      tier_3  credit_card   \n",
              "6   CUST0000001  2024-01         salaried      tier_1  credit_card   \n",
              "7   CUST0000001  2024-02         salaried      tier_1  credit_card   \n",
              "8   CUST0000001  2024-03         salaried      tier_1  credit_card   \n",
              "9   CUST0000001  2024-04         salaried      tier_1  credit_card   \n",
              "10  CUST0000001  2024-05         salaried      tier_1  credit_card   \n",
              "11  CUST0000001  2024-06         salaried      tier_1  credit_card   \n",
              "\n",
              "    active_products_count  credit_card_utilization  total_monthly_obligation  \\\n",
              "0                       2                 0.652587              54470.559453   \n",
              "1                       2                 0.652587              54470.559453   \n",
              "2                       2                 0.652587              54470.559453   \n",
              "3                       2                 0.652587              54470.559453   \n",
              "4                       2                 0.652587              54470.559453   \n",
              "5                       2                 0.652587              54470.559453   \n",
              "6                       1                 0.514368              25741.183454   \n",
              "7                       1                 0.514368              25741.183454   \n",
              "8                       1                 0.514368              25741.183454   \n",
              "9                       1                 0.514368              25741.183454   \n",
              "10                      1                 0.514368              25741.183454   \n",
              "11                      1                 0.514368              25741.183454   \n",
              "\n",
              "    emi_amount  days_to_emi  ...  emi_to_income_ratio_mean_3m  \\\n",
              "0        50220           17  ...                          NaN   \n",
              "1        50220           21  ...                     0.385513   \n",
              "2        50220           10  ...                     0.385513   \n",
              "3        50220           24  ...                     0.385513   \n",
              "4        50220           14  ...                     0.385513   \n",
              "5        50220           19  ...                     0.385513   \n",
              "6        22859           22  ...                          NaN   \n",
              "7        22859           23  ...                     0.203976   \n",
              "8        22859           23  ...                     0.203976   \n",
              "9        22859           19  ...                     0.203976   \n",
              "10       22859           22  ...                     0.203976   \n",
              "11       22859           17  ...                     0.203976   \n",
              "\n",
              "    emi_to_income_ratio_max_3m  emi_to_income_ratio_slope_3m  \\\n",
              "0                          NaN                           NaN   \n",
              "1                     0.385513                           NaN   \n",
              "2                     0.385513                  5.240349e-17   \n",
              "3                     0.385513                  5.240349e-17   \n",
              "4                     0.385513                  5.240349e-17   \n",
              "5                     0.385513                  5.240349e-17   \n",
              "6                          NaN                           NaN   \n",
              "7                     0.203976                           NaN   \n",
              "8                     0.203976                  3.501962e-17   \n",
              "9                     0.203976                  3.501962e-17   \n",
              "10                    0.203976                  3.501962e-17   \n",
              "11                    0.203976                  3.501962e-17   \n",
              "\n",
              "    weekly_balance_change_pct_mean_3m  weekly_balance_change_pct_max_3m  \\\n",
              "0                                 NaN                               NaN   \n",
              "1                           -2.331986                          5.027260   \n",
              "2                            0.096705                          5.027260   \n",
              "3                            1.906092                          5.027260   \n",
              "4                           -2.777736                          4.954088   \n",
              "5                           -6.607963                         -4.263070   \n",
              "6                                 NaN                               NaN   \n",
              "7                          -17.948012                        -16.953144   \n",
              "8                          -18.260893                        -16.953144   \n",
              "9                          -22.938812                        -16.953144   \n",
              "10                         -30.490794                        -18.886654   \n",
              "11                         -30.733064                        -19.613464   \n",
              "\n",
              "    weekly_balance_change_pct_slope_3m  emi_high_persist_3m  \\\n",
              "0                                  NaN                    0   \n",
              "1                                  NaN                    0   \n",
              "2                             7.322660                    0   \n",
              "3                            -4.645165                    0   \n",
              "4                            -6.989157                    0   \n",
              "5                            -1.136761                    0   \n",
              "6                                  NaN                    0   \n",
              "7                                  NaN                    0   \n",
              "8                             0.028113                    0   \n",
              "9                            -8.011747                    0   \n",
              "10                          -10.361218                    0   \n",
              "11                            6.681586                    0   \n",
              "\n",
              "    salary_delay_persist_3m  utilization_high_persist_3m  \\\n",
              "0                         0                            0   \n",
              "1                         0                            0   \n",
              "2                         0                            0   \n",
              "3                         0                            0   \n",
              "4                         0                            0   \n",
              "5                         0                            0   \n",
              "6                         0                            0   \n",
              "7                         0                            0   \n",
              "8                         1                            0   \n",
              "9                         1                            0   \n",
              "10                        1                            0   \n",
              "11                        1                            0   \n",
              "\n",
              "    loan_default_next_month  \n",
              "0                       0.0  \n",
              "1                       1.0  \n",
              "2                       1.0  \n",
              "3                       0.0  \n",
              "4                       0.0  \n",
              "5                       NaN  \n",
              "6                       1.0  \n",
              "7                       1.0  \n",
              "8                       1.0  \n",
              "9                       0.0  \n",
              "10                      1.0  \n",
              "11                      NaN  \n",
              "\n",
              "[12 rows x 78 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "kSPfWMAuFBdx",
        "outputId": "0bfd41e5-5594-41e0-badb-d8fdec6192e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_default_observed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>customer_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CUST0000000</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0000001</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0000002</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0000003</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0000004</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0014995</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0014996</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0014997</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0014998</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUST0014999</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "customer_id\n",
              "CUST0000000    2\n",
              "CUST0000001    4\n",
              "CUST0000002    4\n",
              "CUST0000003    3\n",
              "CUST0000004    1\n",
              "              ..\n",
              "CUST0014995    3\n",
              "CUST0014996    1\n",
              "CUST0014997    2\n",
              "CUST0014998    1\n",
              "CUST0014999    4\n",
              "Name: loan_default_observed, Length: 15000, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(\"customer_id\")[\"loan_default_observed\"].sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztLSG8EXkjjZ"
      },
      "source": [
        "Without Risk Level Latent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C98GWnTzCeJ4",
        "outputId": "b06a9231-fee9-478a-83df-213a7eae57fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.3)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEW-Oi3kCvE7",
        "outputId": "aa64753f-c29a-4489-eb40-233ab13c5529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "786db960",
        "outputId": "e63fc425-02b1-43f1-b1c5-6b54153aace2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:37:32,076] A new study created in memory with name: no-name-c9a3315e-9195-4abd-ad3f-55422b9de5a1\n",
            "[I 2026-02-16 21:37:32,079] A new study created in memory with name: no-name-18d3c9b0-98a0-4c12-8a11-292293320c62\n",
            "[I 2026-02-16 21:37:32,081] A new study created in memory with name: no-name-83d21d34-9820-4628-b727-6a7a47feafe4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:37:48,576] Trial 0 finished with value: 0.8052034463108968 and parameters: {'n_estimators': 312, 'max_depth': 6, 'learning_rate': 0.0639196365086843, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309}. Best is trial 0 with value: 0.8052034463108968.\n",
            "[I 2026-02-16 21:37:58,172] Trial 1 finished with value: 0.8107215880784207 and parameters: {'n_estimators': 246, 'max_depth': 3, 'learning_rate': 0.07197056874649611, 'subsample': 0.8803345035229626, 'colsample_bytree': 0.9124217733388136}. Best is trial 1 with value: 0.8107215880784207.\n",
            "[I 2026-02-16 21:38:18,480] Trial 2 finished with value: 0.8059603220306962 and parameters: {'n_estimators': 206, 'max_depth': 6, 'learning_rate': 0.0699465584480253, 'subsample': 0.7637017332034828, 'colsample_bytree': 0.7545474901621302}. Best is trial 1 with value: 0.8107215880784207.\n",
            "[I 2026-02-16 21:38:32,341] Trial 3 finished with value: 0.8100815445336241 and parameters: {'n_estimators': 255, 'max_depth': 4, 'learning_rate': 0.05148538589793426, 'subsample': 0.8295835055926347, 'colsample_bytree': 0.7873687420594125}. Best is trial 1 with value: 0.8107215880784207.\n",
            "[I 2026-02-16 21:38:45,243] Trial 4 finished with value: 0.8105424802341906 and parameters: {'n_estimators': 384, 'max_depth': 3, 'learning_rate': 0.03752867891211309, 'subsample': 0.8099085529881075, 'colsample_bytree': 0.8368209952651108}. Best is trial 1 with value: 0.8107215880784207.\n",
            "[I 2026-02-16 21:38:58,967] Trial 5 finished with value: 0.8097946529041761 and parameters: {'n_estimators': 436, 'max_depth': 3, 'learning_rate': 0.050854066304816696, 'subsample': 0.8777243706586128, 'colsample_bytree': 0.7139351238159993}. Best is trial 1 with value: 0.8107215880784207.\n",
            "[I 2026-02-16 21:39:07,725] Trial 6 finished with value: 0.8109268405438878 and parameters: {'n_estimators': 382, 'max_depth': 3, 'learning_rate': 0.02390309557911677, 'subsample': 0.984665661176, 'colsample_bytree': 0.9896896099223678}. Best is trial 6 with value: 0.8109268405438878.\n",
            "[I 2026-02-16 21:39:19,706] Trial 7 finished with value: 0.8103902231284711 and parameters: {'n_estimators': 443, 'max_depth': 4, 'learning_rate': 0.025860326840383033, 'subsample': 0.905269907953647, 'colsample_bytree': 0.8320457481218804}. Best is trial 6 with value: 0.8109268405438878.\n",
            "[I 2026-02-16 21:39:27,322] Trial 8 finished with value: 0.8106928525331183 and parameters: {'n_estimators': 236, 'max_depth': 4, 'learning_rate': 0.022063311266913105, 'subsample': 0.9727961206236346, 'colsample_bytree': 0.777633994480005}. Best is trial 6 with value: 0.8109268405438878.\n",
            "[I 2026-02-16 21:39:41,995] Trial 9 finished with value: 0.8091618955224017 and parameters: {'n_estimators': 399, 'max_depth': 4, 'learning_rate': 0.05120408127066865, 'subsample': 0.8640130838029838, 'colsample_bytree': 0.7554563366576581}. Best is trial 6 with value: 0.8109268405438878.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009076 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:40:45,736] Trial 0 finished with value: 0.8003242465461277 and parameters: {'n_estimators': 688, 'learning_rate': 0.051005312934444574, 'num_leaves': 93, 'subsample': 0.9684482051282947, 'colsample_bytree': 0.8793699936433255}. Best is trial 0 with value: 0.8003242465461277.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030035 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015531 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015760 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:41:06,660] Trial 1 finished with value: 0.8071691068551474 and parameters: {'n_estimators': 669, 'learning_rate': 0.02353970008207678, 'num_leaves': 44, 'subsample': 0.7135681866731614, 'colsample_bytree': 0.7975990992289793}. Best is trial 1 with value: 0.8071691068551474.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014979 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014759 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:41:29,126] Trial 2 finished with value: 0.8054773864066354 and parameters: {'n_estimators': 455, 'learning_rate': 0.030853961270955833, 'num_leaves': 85, 'subsample': 0.8070259980080767, 'colsample_bytree': 0.7842803529062142}. Best is trial 1 with value: 0.8071691068551474.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022462 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:42:58,673] Trial 3 finished with value: 0.8056777226005303 and parameters: {'n_estimators': 517, 'learning_rate': 0.025636968998990504, 'num_leaves': 84, 'subsample': 0.7223651931039312, 'colsample_bytree': 0.9960660809801551}. Best is trial 1 with value: 0.8071691068551474.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030408 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:43:23,224] Trial 4 finished with value: 0.8074768643894371 and parameters: {'n_estimators': 609, 'learning_rate': 0.027948627261366897, 'num_leaves': 32, 'subsample': 0.9446384285364502, 'colsample_bytree': 0.9120572031542851}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:43:38,320] Trial 5 finished with value: 0.8042802779860674 and parameters: {'n_estimators': 592, 'learning_rate': 0.050850813867437825, 'num_leaves': 36, 'subsample': 0.8075397185632818, 'colsample_bytree': 0.7347607178575388}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042610 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:44:01,612] Trial 6 finished with value: 0.8024881373155276 and parameters: {'n_estimators': 646, 'learning_rate': 0.04493192507310231, 'num_leaves': 53, 'subsample': 0.7190675050858071, 'colsample_bytree': 0.7932946965146986}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014965 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017161 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015291 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:44:20,167] Trial 7 finished with value: 0.8033221112959567 and parameters: {'n_estimators': 430, 'learning_rate': 0.049184247133522555, 'num_leaves': 73, 'subsample': 0.9661638227728979, 'colsample_bytree': 0.8416644775485848}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016455 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017421 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016386 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:44:39,497] Trial 8 finished with value: 0.8035038964400707 and parameters: {'n_estimators': 347, 'learning_rate': 0.048529791488919796, 'num_leaves': 81, 'subsample': 0.8683831592708489, 'colsample_bytree': 0.9312901539863683}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 8369, number of negative: 15631\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015136 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348708 -> initscore=-0.624722\n",
            "[LightGBM] [Info] Start training from score -0.624722\n",
            "[LightGBM] [Info] Number of positive: 8311, number of negative: 15689\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346292 -> initscore=-0.635380\n",
            "[LightGBM] [Info] Start training from score -0.635380\n",
            "[LightGBM] [Info] Number of positive: 8318, number of negative: 15682\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014896 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10005\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346583 -> initscore=-0.634092\n",
            "[LightGBM] [Info] Start training from score -0.634092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:44:57,726] Trial 9 finished with value: 0.8050242195914535 and parameters: {'n_estimators': 498, 'learning_rate': 0.04090931317527976, 'num_leaves': 59, 'subsample': 0.7076257380232285, 'colsample_bytree': 0.7323674280979913}. Best is trial 4 with value: 0.8074768643894371.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning CatBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2026-02-16 21:45:55,457] Trial 0 finished with value: 0.8108872398617848 and parameters: {'iterations': 312, 'depth': 7, 'learning_rate': 0.03257423924305307}. Best is trial 0 with value: 0.8108872398617848.\n",
            "[I 2026-02-16 21:48:02,760] Trial 1 finished with value: 0.8097338119468187 and parameters: {'iterations': 503, 'depth': 8, 'learning_rate': 0.029971689165954996}. Best is trial 0 with value: 0.8108872398617848.\n",
            "[I 2026-02-16 21:49:58,830] Trial 2 finished with value: 0.810376575869476 and parameters: {'iterations': 464, 'depth': 8, 'learning_rate': 0.029151926619664897}. Best is trial 0 with value: 0.8108872398617848.\n",
            "[I 2026-02-16 21:50:44,590] Trial 3 finished with value: 0.810985294657948 and parameters: {'iterations': 330, 'depth': 6, 'learning_rate': 0.026448851490160175}. Best is trial 3 with value: 0.810985294657948.\n",
            "[I 2026-02-16 21:53:35,142] Trial 4 finished with value: 0.8065133011871669 and parameters: {'iterations': 672, 'depth': 8, 'learning_rate': 0.04533615026041694}. Best is trial 3 with value: 0.810985294657948.\n",
            "[I 2026-02-16 21:56:19,549] Trial 5 finished with value: 0.8088587116755989 and parameters: {'iterations': 649, 'depth': 8, 'learning_rate': 0.027462802355441435}. Best is trial 3 with value: 0.810985294657948.\n",
            "[I 2026-02-16 21:58:18,167] Trial 6 finished with value: 0.8073476844336706 and parameters: {'iterations': 657, 'depth': 7, 'learning_rate': 0.0522976062065625}. Best is trial 3 with value: 0.810985294657948.\n",
            "[I 2026-02-16 21:59:50,344] Trial 7 finished with value: 0.8108136988335973 and parameters: {'iterations': 659, 'depth': 6, 'learning_rate': 0.02440207698110707}. Best is trial 3 with value: 0.810985294657948.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 12499, number of negative: 23501\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007267 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10006\n",
            "[LightGBM] [Info] Number of data points in the train set: 36000, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.347194 -> initscore=-0.631394\n",
            "[LightGBM] [Info] Start training from score -0.631394\n",
            "XGB AUC: 0.8109268405438878\n",
            "LGB AUC: 0.8074768643894371\n",
            "CAT AUC: 0.810985294657948\n",
            "\n",
            "HOLDOUT ENSEMBLE AUC: 0.8172385933110882\n",
            "Tree aligned preds shape: (3000,)\n",
            "Tree aligned actuals shape: (3000,)\n",
            "\n",
            "TREE HOLDOUT AUC (Aligned 3000): 0.8250300780850679\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "\n",
        "# LOAD DATA\n",
        "\n",
        "# Make the original raw dataframe globally accessible\n",
        "global df_base_raw_global\n",
        "df_base_raw_global = pd.read_csv(\"financial_stress_full_bank_grade_dataset.csv\")\n",
        "\n",
        "df = df_base_raw_global.sort_values([\"customer_id\",\"month\"]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# DEFINE NUMERIC FEATURES\n",
        "\n",
        "NUMERIC_COLS = [\n",
        "    \"active_products_count\",\n",
        "    \"credit_card_utilization\",\n",
        "    \"total_monthly_obligation\",\n",
        "    \"emi_amount\",\n",
        "    \"days_to_emi\",\n",
        "    \"emi_to_income_ratio\",\n",
        "    \"salary_delay_days\",\n",
        "    \"weekly_balance_change_pct\",\n",
        "    \"atm_withdrawal_amount\",\n",
        "    \"monthly_income\"\n",
        "]\n",
        "\n",
        "\n",
        "# LAG FEATURES (NO risk_level_latent)\n",
        "\n",
        "for col in NUMERIC_COLS:\n",
        "    df[f\"{col}_lag1\"] = df.groupby(\"customer_id\")[col].shift(1)\n",
        "    df[f\"{col}_lag2\"] = df.groupby(\"customer_id\")[col].shift(2)\n",
        "\n",
        "\n",
        "\n",
        "# DELTA FEATURES\n",
        "\n",
        "for col in NUMERIC_COLS:\n",
        "    df[f\"{col}_delta_1\"] = df[col] - df[f\"{col}_lag1\"]\n",
        "    df[f\"{col}_delta_2\"] = df[f\"{col}_lag1\"] - df[f\"{col}_lag2\"]\n",
        "\n",
        "\n",
        "\n",
        "# VOLATILITY FEATURES\n",
        "\n",
        "VOL_COLS = [\n",
        "    \"credit_card_utilization\",\n",
        "    \"weekly_balance_change_pct\",\n",
        "    \"monthly_income\"\n",
        "]\n",
        "\n",
        "for col in VOL_COLS:\n",
        "    df[f\"{col}_std_3m\"] = (\n",
        "        df.groupby(\"customer_id\")[col]\n",
        "        .rolling(3, min_periods=2)\n",
        "        .std()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# ROLLING FEATURES\n",
        "\n",
        "ROLLING_COLS = [\n",
        "    \"credit_card_utilization\",\n",
        "    \"monthly_income\",\n",
        "    \"emi_to_income_ratio\",\n",
        "    \"weekly_balance_change_pct\"\n",
        "]\n",
        "\n",
        "for col in ROLLING_COLS:\n",
        "    g = df.groupby(\"customer_id\")[col]\n",
        "\n",
        "    df[f\"{col}_mean_3m\"] = (\n",
        "        g.rolling(3, min_periods=2)\n",
        "        .mean()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    df[f\"{col}_max_3m\"] = (\n",
        "        g.rolling(3, min_periods=2)\n",
        "        .max()\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "    df[f\"{col}_slope_3m\"] = (\n",
        "        g.rolling(3, min_periods=3)\n",
        "        .apply(lambda x: np.polyfit(range(len(x)), x, 1)[0])\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# PERSISTENCE FLAGs\n",
        "\n",
        "df[\"emi_high_persist_3m\"] = (\n",
        "    (df[\"emi_to_income_ratio\"] > 0.40)\n",
        "    .groupby(df[\"customer_id\"])\n",
        "    .rolling(3, min_periods=3)\n",
        "    .sum()\n",
        "    .ge(2)\n",
        "    .reset_index(level=0, drop=True)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "df[\"salary_delay_persist_3m\"] = (\n",
        "    (df[\"salary_delay_days\"] > 5)\n",
        "    .groupby(df[\"customer_id\"])\n",
        "    .rolling(3, min_periods=3)\n",
        "    .sum()\n",
        "    .ge(2)\n",
        "    .reset_index(level=0, drop=True)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "df[\"utilization_high_persist_3m\"] = (\n",
        "    (df[\"credit_card_utilization\"] > 0.75)\n",
        "    .groupby(df[\"customer_id\"])\n",
        "    .rolling(3, min_periods=3)\n",
        "    .sum()\n",
        "    .ge(2)\n",
        "    .reset_index(level=0, drop=True)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# Next month target\n",
        "df[\"loan_default_next_month\"] = (\n",
        "    df.groupby(\"customer_id\")[\"loan_default_observed\"].shift(-1)\n",
        ")\n",
        "\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Make the processed dataframe for tree models globally accessible\n",
        "global df_processed_tree_global\n",
        "df_processed_tree_global = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "# HOLDOUT SPLIT (NO LEAKAGE)\n",
        "\n",
        "customers = df[\"customer_id\"].unique()\n",
        "\n",
        "global train_ids_global\n",
        "global holdout_ids_global\n",
        "train_ids_global, holdout_ids_global = train_test_split(\n",
        "    customers,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "global train_df_tree_global\n",
        "train_df_tree_global = df[df.customer_id.isin(train_ids_global)].reset_index(drop=True)\n",
        "global holdout_df\n",
        "holdout_df = df[df.customer_id.isin(holdout_ids_global)].reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# FEATURE / TARGET SPLIT (TRAIN ONLY)\n",
        "\n",
        "DROP_COLS = [\n",
        "    \"customer_id\",\"month\",\n",
        "    \"loan_default_observed\",\n",
        "    \"loan_default_next_month\"\n",
        "]\n",
        "\n",
        "X = train_df_tree_global.drop(columns=DROP_COLS)\n",
        "y = train_df_tree_global[\"loan_default_next_month\"]\n",
        "groups = train_df_tree_global[\"customer_id\"]\n",
        "\n",
        "\n",
        "\n",
        "# ONE HOT ENCODING (TRAIN ONLY)\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "X_ohe = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "TREE_FEATURE_COLUMNS = X_ohe.columns.tolist()\n",
        "joblib.dump(TREE_FEATURE_COLUMNS, \"models/tree_feature_columns.pkl\")\n",
        "\n",
        "\n",
        "# PREPARE HOLDOUT MATRICES\n",
        "\n",
        "X_holdout = holdout_df.drop(columns=DROP_COLS)\n",
        "y_holdout = holdout_df[\"loan_default_next_month\"]\n",
        "\n",
        "X_holdout_ohe = pd.get_dummies(X_holdout, columns=cat_cols, drop_first=True)\n",
        "\n",
        "# Align columns\n",
        "X_holdout_ohe = X_holdout_ohe.reindex(columns=X_ohe.columns, fill_value=0)\n",
        "\n",
        "# Make the tree model's full holdout set globally accessible\n",
        "global test_df_tree_global\n",
        "test_df_tree_global = holdout_df.copy()\n",
        "\n",
        "\n",
        "\n",
        "# GROUP CV (TRAIN ONLY)\n",
        "\n",
        "gkf = GroupKFold(n_splits=3)\n",
        "\n",
        "\n",
        "\n",
        "# XGBOOST OBJECTIVE\n",
        "\n",
        "def objective_xgb(trial):\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\",200,500),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\",3,6),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\",0.02,0.08),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\",0.7,1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.7,1.0),\n",
        "        \"eval_metric\":\"logloss\",\n",
        "        \"random_state\":42,\n",
        "        \"n_jobs\":-1\n",
        "    }\n",
        "\n",
        "    aucs = []\n",
        "\n",
        "    for fold,(tr,va) in enumerate(gkf.split(X_ohe,y,groups)):\n",
        "\n",
        "        Xtr,Xva = X_ohe.iloc[tr],X_ohe.iloc[va]\n",
        "        ytr,yva = y.iloc[tr],y.iloc[va]\n",
        "\n",
        "        spw = (ytr==0).sum()/(ytr==1).sum()\n",
        "\n",
        "        model = XGBClassifier(scale_pos_weight=spw,**params)\n",
        "        model.fit(Xtr,ytr)\n",
        "\n",
        "        p = model.predict_proba(Xva)[:,1]\n",
        "        auc = roc_auc_score(yva,p)\n",
        "\n",
        "        aucs.append(auc)\n",
        "\n",
        "    return np.mean(aucs)\n",
        "\n",
        "\n",
        "\n",
        "# LIGHTGBM OBJECTIVE\n",
        "\n",
        "def objective_lgb(trial):\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\",300,700),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\",0.02,0.06),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\",32,96),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\",0.7,1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.7,1.0),\n",
        "        \"random_state\":42,\n",
        "        \"n_jobs\":-1\n",
        "    }\n",
        "\n",
        "    aucs = []\n",
        "\n",
        "    for fold,(tr,va) in enumerate(gkf.split(X_ohe,y,groups)):\n",
        "\n",
        "        Xtr,Xva = X_ohe.iloc[tr],X_ohe.iloc[va]\n",
        "        ytr,yva = y.iloc[tr],y.iloc[va]\n",
        "\n",
        "        spw = (ytr==0).sum()/(ytr==1).sum()\n",
        "\n",
        "        model = LGBMClassifier(scale_pos_weight=spw,**params)\n",
        "        model.fit(Xtr,ytr)\n",
        "\n",
        "        p = model.predict_proba(Xva)[:,1]\n",
        "        auc = roc_auc_score(yva,p)\n",
        "\n",
        "        aucs.append(auc)\n",
        "\n",
        "    return np.mean(aucs)\n",
        "\n",
        "\n",
        "\n",
        "# CATBOOST OBJECTIVE\n",
        "\n",
        "cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
        "\n",
        "def objective_cat(trial):\n",
        "\n",
        "    params = {\n",
        "        \"iterations\": trial.suggest_int(\"iterations\",300,700),\n",
        "        \"depth\": trial.suggest_int(\"depth\",5,8),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\",0.02,0.06),\n",
        "        \"loss_function\":\"Logloss\",\n",
        "        \"eval_metric\":\"AUC\",\n",
        "        \"random_seed\":42,\n",
        "        \"verbose\":0\n",
        "    }\n",
        "\n",
        "    aucs = []\n",
        "\n",
        "    for fold,(tr,va) in enumerate(gkf.split(X,y,groups)):\n",
        "\n",
        "        Xtr,Xva = X.iloc[tr],X.iloc[va]\n",
        "        ytr,yva = y.iloc[tr],y.iloc[va]\n",
        "\n",
        "        spw = (ytr==0).sum()/(ytr==1).sum()\n",
        "\n",
        "        model = CatBoostClassifier(scale_pos_weight=spw,**params)\n",
        "        model.fit(Xtr,ytr,cat_features=cat_idx)\n",
        "\n",
        "        p = model.predict_proba(Xva)[:,1]\n",
        "        auc = roc_auc_score(yva,p)\n",
        "\n",
        "        aucs.append(auc)\n",
        "\n",
        "    return np.mean(aucs)\n",
        "\n",
        "\n",
        "\n",
        "# RUN OPTUNA (TRAIN ONLY)\n",
        "\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "\n",
        "study_xgb = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "study_lgb = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "study_cat = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "\n",
        "print(\"Tuning XGBoost...\")\n",
        "study_xgb.optimize(objective_xgb, n_trials=10)\n",
        "\n",
        "print(\"Tuning LightGBM...\")\n",
        "study_lgb.optimize(objective_lgb, n_trials=10)\n",
        "\n",
        "print(\"Tuning CatBoost...\")\n",
        "study_cat.optimize(objective_cat, n_trials=8)\n",
        "\n",
        "\n",
        "\n",
        "# TRAIN FINAL MODELS (TRAIN DATA ONLY)\n",
        "\n",
        "spw = (y==0).sum()/(y==1).sum()\n",
        "\n",
        "global xgb\n",
        "global lgb\n",
        "global cat\n",
        "xgb = XGBClassifier(scale_pos_weight=spw,**study_xgb.best_params)\n",
        "lgb = LGBMClassifier(scale_pos_weight=spw,**study_lgb.best_params)\n",
        "cat = CatBoostClassifier(scale_pos_weight=spw,**study_cat.best_params,verbose=0)\n",
        "\n",
        "xgb.fit(X_ohe,y)\n",
        "lgb.fit(X_ohe,y)\n",
        "cat.fit(X_ohe,y)\n",
        "\n",
        "\n",
        "\n",
        "# HOLDOUT EVALUATION (REAL PERFORMANCE)\n",
        "\n",
        "px = xgb.predict_proba(X_holdout_ohe)[:,1]\n",
        "pl = lgb.predict_proba(X_holdout_ohe)[:,1]\n",
        "pc = cat.predict_proba(X_holdout_ohe)[:,1]\n",
        "\n",
        "wx = study_xgb.best_value\n",
        "wl = study_lgb.best_value\n",
        "wc = study_cat.best_value\n",
        "\n",
        "s = wx+wl+wc\n",
        "\n",
        "final = (wx*px + wl*pl + wc*pc)/s\n",
        "\n",
        "print(\"XGB AUC:\", wx)\n",
        "print(\"LGB AUC:\", wl)\n",
        "print(\"CAT AUC:\", wc)\n",
        "\n",
        "\n",
        "# Store tree predictions for alignment\n",
        "global tree_preds_full_holdout\n",
        "tree_preds_full_holdout = pd.Series(final, index=test_df_tree_global.index)\n",
        "\n",
        "# Filter tree predictions to include only the last available observation for each customer in holdout_ids_global\n",
        "global tree_preds_aligned_for_hybrid\n",
        "tree_preds_aligned_for_hybrid = tree_preds_full_holdout.loc[test_df_tree_global.groupby('customer_id').tail(1).index]\n",
        "\n",
        "print(\"\\nHOLDOUT ENSEMBLE AUC:\", roc_auc_score(y_holdout,final))\n",
        "\n",
        "\n",
        "# ALIGN TRUE TARGETS FOR HYBRID (LAST MONTH ONLY)\n",
        "\n",
        "\n",
        "# Get the last observation per customer (same rows used for LSTM)\n",
        "global holdout_last_rows\n",
        "holdout_last_rows = test_df_tree_global.groupby(\"customer_id\").tail(1)\n",
        "\n",
        "global y_holdout_aligned\n",
        "y_holdout_aligned = holdout_last_rows[\"loan_default_next_month\"].values\n",
        "\n",
        "print(\"Tree aligned preds shape:\", tree_preds_aligned_for_hybrid.shape)\n",
        "print(\"Tree aligned actuals shape:\", y_holdout_aligned.shape)\n",
        "\n",
        "\n",
        "# TREE AUC ON SAME 3000 CUSTOMERS\n",
        "\n",
        "\n",
        "tree_holdout_aligned_auc = roc_auc_score(\n",
        "    y_holdout_aligned,\n",
        "    tree_preds_aligned_for_hybrid.values\n",
        ")\n",
        "\n",
        "print(\"\\nTREE HOLDOUT AUC (Aligned 3000):\", tree_holdout_aligned_auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "431f529d",
        "outputId": "2e7d4d35-5ef3-485c-cd78-6374cd94cdf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Train size: 12000\n",
            "LSTM Holdout size: 3000\n",
            "Epoch 1/15 - Train Loss: 0.5537\n",
            "Epoch 2/15 - Train Loss: 0.5139\n",
            "Epoch 3/15 - Train Loss: 0.5092\n",
            "Epoch 4/15 - Train Loss: 0.5063\n",
            "Epoch 5/15 - Train Loss: 0.5059\n",
            "Epoch 6/15 - Train Loss: 0.5075\n",
            "Epoch 7/15 - Train Loss: 0.5057\n",
            "Epoch 8/15 - Train Loss: 0.5044\n",
            "Epoch 9/15 - Train Loss: 0.5036\n",
            "Epoch 10/15 - Train Loss: 0.5047\n",
            "Epoch 11/15 - Train Loss: 0.5033\n",
            "Epoch 12/15 - Train Loss: 0.5033\n",
            "Epoch 13/15 - Train Loss: 0.5023\n",
            "Epoch 14/15 - Train Loss: 0.5018\n",
            "Epoch 15/15 - Train Loss: 0.5014\n",
            "LSTM HOLDOUT AUC: 0.8212939081065354\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# LSTM PRE-DELINQUENCY MODEL (RAW FEATURES ONLY)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "# CONFIG\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "SEQUENCE_LENGTH = 3\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15\n",
        "LR = 1e-3\n",
        "HIDDEN_SIZE = 64\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "# LOAD RAW DATA ONLY\n",
        "\n",
        "\n",
        "df = df_base_raw_global.copy()\n",
        "df = df.sort_values([\"customer_id\", \"month\"]).reset_index(drop=True)\n",
        "\n",
        "# Create next month target\n",
        "df[\"loan_default_next_month\"] = (\n",
        "    df.groupby(\"customer_id\")[\"loan_default_observed\"].shift(-1)\n",
        ")\n",
        "\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Remove leakage column if exists\n",
        "if \"risk_level_latent\" in df.columns:\n",
        "    df = df.drop(columns=[\"risk_level_latent\"])\n",
        "\n",
        "\n",
        "\n",
        "# DEFINE RAW FEATURES ONLY\n",
        "\n",
        "\n",
        "RAW_NUMERIC_FEATURES = [\n",
        "    \"active_products_count\",\n",
        "    \"credit_card_utilization\",\n",
        "    \"total_monthly_obligation\",\n",
        "    \"emi_amount\",\n",
        "    \"days_to_emi\",\n",
        "    \"emi_to_income_ratio\",\n",
        "    \"salary_delay_days\",\n",
        "    \"weekly_balance_change_pct\",\n",
        "    \"atm_withdrawal_amount\",\n",
        "    \"monthly_income\"\n",
        "]\n",
        "\n",
        "ID_COLS = [\"customer_id\", \"month\"]\n",
        "\n",
        "# Handle categorical columns (if present)\n",
        "cat_cols = [\n",
        "    c for c in df.select_dtypes(include=[\"object\"]).columns\n",
        "    if c not in ID_COLS\n",
        "]\n",
        "\n",
        "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "\n",
        "# Final LSTM feature list\n",
        "DROP_COLS = [\n",
        "    \"customer_id\",\n",
        "    \"month\",\n",
        "    \"loan_default_observed\",\n",
        "    \"loan_default_next_month\"\n",
        "]\n",
        "\n",
        "LSTM_FEATURE_COLS = [c for c in df.columns if c not in DROP_COLS]\n",
        "\n",
        "\n",
        "\n",
        "# CREATE SEQUENCES (RAW FEATURES ONLY)\n",
        "\n",
        "\n",
        "sequence_data = []\n",
        "targets = []\n",
        "customer_ids = []\n",
        "\n",
        "for cust in df[\"customer_id\"].unique():\n",
        "    cust_df = df[df.customer_id == cust].sort_values(\"month\")\n",
        "\n",
        "    if len(cust_df) < SEQUENCE_LENGTH:\n",
        "        continue\n",
        "\n",
        "    values = cust_df[LSTM_FEATURE_COLS].values\n",
        "    y_vals = cust_df[\"loan_default_next_month\"].values\n",
        "\n",
        "    seq = values[-SEQUENCE_LENGTH:]\n",
        "    target = y_vals[-1]\n",
        "\n",
        "    sequence_data.append(seq)\n",
        "    targets.append(target)\n",
        "    customer_ids.append(cust)\n",
        "\n",
        "X_seq_all = np.array(sequence_data)\n",
        "y_seq_all = np.array(targets)\n",
        "groups_seq_all = np.array(customer_ids)\n",
        "\n",
        "\n",
        "\n",
        "# ALIGN WITH TREE HOLDOUT SPLIT\n",
        "\n",
        "\n",
        "train_mask = np.isin(groups_seq_all, train_ids_global)\n",
        "holdout_mask = np.isin(groups_seq_all, holdout_ids_global)\n",
        "\n",
        "X_train = X_seq_all[train_mask]\n",
        "y_train = y_seq_all[train_mask]\n",
        "\n",
        "X_holdout = X_seq_all[holdout_mask]\n",
        "y_holdout_lstm = y_seq_all[holdout_mask]\n",
        "\n",
        "print(\"LSTM Train size:\", X_train.shape[0])\n",
        "print(\"LSTM Holdout size:\", X_holdout.shape[0])\n",
        "\n",
        "\n",
        "\n",
        "# SCALE RAW FEATURES\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_holdout_2d = X_holdout.reshape(-1, X_holdout.shape[-1])\n",
        "\n",
        "scaler.fit(X_train_2d)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
        "X_holdout_scaled = scaler.transform(X_holdout_2d).reshape(X_holdout.shape)\n",
        "\n",
        "\n",
        "\n",
        "# DATASET CLASS\n",
        "\n",
        "\n",
        "class StressDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    StressDataset(X_train_scaled, y_train),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "holdout_loader = DataLoader(\n",
        "    StressDataset(X_holdout_scaled, y_holdout_lstm),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# LSTM MODEL\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.dropout(out)\n",
        "        out = torch.sigmoid(self.fc(out))\n",
        "        return out.squeeze()\n",
        "\n",
        "\n",
        "model = LSTMModel(input_size=len(LSTM_FEATURE_COLS)).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "\n",
        "# TRAIN LOOP\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X_batch)\n",
        "\n",
        "        loss = criterion(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# HOLDOUT EVALUATION\n",
        "\n",
        "\n",
        "model.eval()\n",
        "lstm_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in holdout_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        preds = model(X_batch)\n",
        "        lstm_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "lstm_preds = np.array(lstm_preds)\n",
        "\n",
        "print(\"LSTM HOLDOUT AUC:\", roc_auc_score(y_holdout_lstm, lstm_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce2Bkh80DQ5c",
        "outputId": "ba1c0b65-46f0-4089-d5e4-28079a905ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "print(len(LSTM_FEATURE_COLS))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5faead",
        "outputId": "e4b2e562-335f-4ac9-e66e-5494a547d8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tree preds shape: (3000,)\n",
            "LSTM preds shape: (3000,)\n",
            "Hybrid actuals shape: (3000,)\n",
            "\n",
            "HYBRID AUC (Simple Average): 0.8238284290982867\n",
            "HYBRID AUC (Weighted 0.6 Tree / 0.4 LSTM): 0.8243808436018212\n",
            "\n",
            "Best Weight for Trees: 0.9\n",
            "Best Hybrid AUC: 0.8249937091586786\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# FINAL HYBRID MODEL (TREES + LSTM)\n",
        "\n",
        "\n",
        "# Ensure both are numpy arrays\n",
        "tree_preds = np.array(tree_preds_aligned_for_hybrid) # Use the aligned tree predictions\n",
        "lstm_preds = np.array(lstm_preds) # Use the LSTM predictions\n",
        "y_hybrid_actuals = np.array(y_holdout_aligned_for_lstm) # Use the aligned actual targets\n",
        "\n",
        "print(\"Tree preds shape:\", tree_preds.shape)\n",
        "print(\"LSTM preds shape:\", lstm_preds.shape)\n",
        "print(\"Hybrid actuals shape:\", y_hybrid_actuals.shape)\n",
        "\n",
        "# SIMPLE AVERAGE\n",
        "hybrid_preds_avg = (tree_preds + lstm_preds) / 2\n",
        "\n",
        "hybrid_auc_avg = roc_auc_score(y_hybrid_actuals, hybrid_preds_avg)\n",
        "\n",
        "print(\"\\nHYBRID AUC (Simple Average):\", hybrid_auc_avg)\n",
        "\n",
        "\n",
        "# WEIGHTED BLEND\n",
        "TREE_WEIGHT = 0.6\n",
        "LSTM_WEIGHT = 0.4\n",
        "\n",
        "hybrid_preds_weighted = (\n",
        "    TREE_WEIGHT * tree_preds +\n",
        "    LSTM_WEIGHT * lstm_preds\n",
        ")\n",
        "\n",
        "hybrid_auc_weighted = roc_auc_score(y_hybrid_actuals, hybrid_preds_weighted)\n",
        "\n",
        "print(\"HYBRID AUC (Weighted 0.6 Tree / 0.4 LSTM):\", hybrid_auc_weighted)\n",
        "\n",
        "\n",
        "# OPTIMAL WEIGHT SEARCH\n",
        "best_auc = 0\n",
        "global best_weight\n",
        "best_weight = 0\n",
        "\n",
        "for w in np.arange(0, 1.01, 0.05):\n",
        "    blended = w * tree_preds + (1 - w) * lstm_preds\n",
        "    auc = roc_auc_score(y_hybrid_actuals, blended)\n",
        "\n",
        "    if auc > best_auc:\n",
        "        best_auc = auc\n",
        "        best_weight = w\n",
        "\n",
        "print(\"\\nBest Weight for Trees:\", round(best_weight,2))\n",
        "print(\"Best Hybrid AUC:\", best_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsIEKCO6kQ9-",
        "outputId": "d0b6e946-42e5-4f15-b32b-c963c7772ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Hybrid PD built using best weight.\n",
            "Calibrated Mean PD: 0.34532333333333326\n",
            "Original Mean PD: 0.4548876163674662\n",
            "\n",
            "Top 5 Customers by Expected Loss:\n",
            "   customer_id        PD   LGD            EAD  Expected_Loss\n",
            "0  CUST0013187  0.847291  0.55  604258.298917  281590.320579\n",
            "1  CUST0001491  0.950000  0.55  507474.605889  265155.481577\n",
            "2  CUST0003297  0.892857  0.55  520938.057576  255817.796131\n",
            "3  CUST0000499  0.923077  0.55  478112.199964  242733.886136\n",
            "4  CUST0010236  0.847291  0.55  516100.786868  240508.051417\n",
            "5  CUST0012665  0.847291  0.55  494983.305500  230667.097046\n",
            "6  CUST0003643  0.892857  0.55  465855.564764  228768.357697\n",
            "7  CUST0005620  0.847291  0.55  458226.908303  213538.253820\n",
            "8  CUST0009862  0.923077  0.45  502282.849933  208640.568434\n",
            "9  CUST0002357  0.759690  0.55  487204.517309  203568.399093\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# BUILD FINAL HYBRID PD USING BEST WEIGHT\n",
        "\n",
        "\n",
        "best_blended_preds = (\n",
        "    best_weight * tree_preds +\n",
        "    (1 - best_weight) * lstm_preds\n",
        ")\n",
        "\n",
        "print(\"\\nFinal Hybrid PD built using best weight.\")\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "\n",
        "# CALIBRATION USING HOLDOUT (POST-PROCESSING)\n",
        "\n",
        "\n",
        "iso = IsotonicRegression(out_of_bounds='clip')\n",
        "\n",
        "iso.fit(best_blended_preds, y_hybrid_actuals)\n",
        "\n",
        "calibrated_pd = iso.predict(best_blended_preds)\n",
        "\n",
        "# Production safety cap\n",
        "calibrated_pd = np.clip(calibrated_pd, 0.01, 0.95)\n",
        "\n",
        "\n",
        "print(\"Calibrated Mean PD:\", calibrated_pd.mean())\n",
        "print(\"Original Mean PD:\", best_blended_preds.mean())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# EXPECTED LOSS ENGINE (PD Ã— LGD Ã— EAD)\n",
        "\n",
        "\n",
        "# Get aligned holdout rows (same 3000 customers used in hybrid)\n",
        "holdout_last_rows = test_df_tree_global.groupby(\"customer_id\").tail(1)\n",
        "\n",
        "#  PD\n",
        "pd_scores = calibrated_pd  # (3000,)\n",
        "\n",
        "#  EAD (Exposure At Default)\n",
        "# Assume 6 months remaining EMI\n",
        "ead = (\n",
        "    holdout_last_rows[\"emi_amount\"] * 6 +\n",
        "    holdout_last_rows[\"credit_card_utilization\"] *\n",
        "    holdout_last_rows[\"monthly_income\"] * 2\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#  LGD (Loss Given Default)\n",
        "lgd = (\n",
        "    0.35 +\n",
        "    0.1 * holdout_last_rows[\"salary_delay_persist_3m\"] +\n",
        "    0.1 * holdout_last_rows[\"utilization_high_persist_3m\"]\n",
        ")   # between 40% and 60%\n",
        "\n",
        "#  EXPECTED LOSS\n",
        "expected_loss = pd_scores * lgd * ead\n",
        "\n",
        "\n",
        "# CREATE RISK OUTPUT TABLE\n",
        "\n",
        "\n",
        "# Reset index to guarantee order alignment with predictions\n",
        "risk_output_df = holdout_last_rows.reset_index(drop=True).copy()\n",
        "\n",
        "# Add model outputs\n",
        "risk_output_df[\"PD\"] = calibrated_pd\n",
        "risk_output_df[\"LGD\"] = lgd.values\n",
        "risk_output_df[\"EAD\"] = ead.values\n",
        "\n",
        "risk_output_df[\"Expected_Loss\"] = (\n",
        "    risk_output_df[\"PD\"] *\n",
        "    risk_output_df[\"LGD\"] *\n",
        "    risk_output_df[\"EAD\"]\n",
        ")\n",
        "\n",
        "# Rank customers by Expected Loss\n",
        "risk_output_df = risk_output_df.sort_values(\n",
        "    \"Expected_Loss\", ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 5 Customers by Expected Loss:\")\n",
        "print(\n",
        "    risk_output_df[\n",
        "        [\"customer_id\",\"PD\",\"LGD\",\"EAD\",\"Expected_Loss\"]\n",
        "    ].head(10)\n",
        ")\n",
        "\n",
        "\n",
        "# Default Rate = 0.345\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv-3mfJPoT6G",
        "outputId": "4f749692-6648-4f45-ebca-6b21051acaf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean PD: 0.34532333333333326\n",
            "Median PD: 0.225\n",
            "Min PD: 0.01\n",
            "Max PD: 0.95\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean PD:\", risk_output_df[\"PD\"].mean())\n",
        "print(\"Median PD:\", risk_output_df[\"PD\"].median())\n",
        "print(\"Min PD:\", risk_output_df[\"PD\"].min())\n",
        "print(\"Max PD:\", risk_output_df[\"PD\"].max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "dNFj31AcoaT1",
        "outputId": "926c8f46-aef7-4ea3-99ac-6a6060cba61e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "risk_output_df[\"PD\"].hist(bins=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZM1rVSXoijC",
        "outputId": "9b1e564b-c22a-4fa2-e3f0-32a6416c168d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual default rate: 0.3453333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Actual default rate:\",\n",
        "      y_holdout_aligned.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUjz2yp7o4ck",
        "outputId": "4f4759b7-f029-43d6-f0a4-17ca585732c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brier Score: 0.15346681940135753\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "print(\"Brier Score:\",\n",
        "      brier_score_loss(y_hybrid_actuals, calibrated_pd))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8DlWUaxtHdt",
        "outputId": "9b4fc6eb-86cf-4e3c-ea8e-7f237becc208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Hybrid PD built using best weight.\n",
            "Calibrated Mean PD: 0.34539782356543786\n",
            "Original Mean PD: 0.4548876163674662\n",
            "\n",
            "Top 5 Customers by Expected Loss:\n",
            "   customer_id        PD   LGD            EAD  Expected_Loss\n",
            "0  CUST0013187  0.789713  0.55  604258.298917  262454.981878\n",
            "1  CUST0003297  0.797958  0.55  520938.057576  228627.594224\n",
            "2  CUST0001491  0.810227  0.55  507474.605889  226143.328869\n",
            "3  CUST0010236  0.779683  0.55  516100.786868  221317.193197\n",
            "4  CUST0012665  0.777607  0.55  494983.305500  211696.391870\n",
            "5  CUST0000499  0.802387  0.55  478112.199964  210996.944507\n",
            "6  CUST0003643  0.796927  0.55  465855.564764  204188.996346\n",
            "7  CUST0002357  0.751387  0.55  487204.517309  201343.400292\n",
            "8  CUST0005620  0.787363  0.55  458226.908303  198434.962266\n",
            "9  CUST0003776  0.793460  0.55  432715.189117  188838.158868\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# BUILD FINAL HYBRID PD USING BEST WEIGHT\n",
        "\n",
        "\n",
        "best_blended_preds = (\n",
        "    best_weight * tree_preds +\n",
        "    (1 - best_weight) * lstm_preds\n",
        ")\n",
        "\n",
        "print(\"\\nFinal Hybrid PD built using best weight.\")\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "global calibrator\n",
        "calibrator = LogisticRegression()\n",
        "calibrator.fit(best_blended_preds.reshape(-1,1), y_hybrid_actuals)\n",
        "\n",
        "calibrated_pd = calibrator.predict_proba(\n",
        "    best_blended_preds.reshape(-1,1)\n",
        ")[:,1]\n",
        "\n",
        "# Production safety cap\n",
        "calibrated_pd = np.clip(calibrated_pd, 0.01, 0.95)\n",
        "\n",
        "\n",
        "print(\"Calibrated Mean PD:\", calibrated_pd.mean())\n",
        "print(\"Original Mean PD:\", best_blended_preds.mean())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# EXPECTED LOSS ENGINE (PD \\u00d7 LGD \\u00d7 EAD)\n",
        "\n",
        "\n",
        "# Get aligned holdout rows (same 3000 customers used in hybrid)\n",
        "holdout_last_rows = test_df_tree_global.groupby(\"customer_id\").tail(1)\n",
        "\n",
        "#  PD\n",
        "pd_scores = calibrated_pd  # (3000,)\n",
        "\n",
        "#  EAD (Exposure At Default)\n",
        "# Assume 6 months remaining EMI\n",
        "ead = (\n",
        "    holdout_last_rows[\"emi_amount\"] * 6 +\n",
        "    holdout_last_rows[\"credit_card_utilization\"] *\n",
        "    holdout_last_rows[\"monthly_income\"] * 2\n",
        ")\n",
        "\n",
        "# Check for missing persistence features and assign default if not found\n",
        "salary_delay_persist_series = 0\n",
        "if \"salary_delay_persist_3m\" in holdout_last_rows.columns:\n",
        "    salary_delay_persist_series = holdout_last_rows[\"salary_delay_persist_3m\"]\n",
        "else:\n",
        "    print(\"Warning: 'salary_delay_persist_3m' not found in holdout_last_rows. Defaulting to 0 for LGD calculation.\")\n",
        "    salary_delay_persist_series = pd.Series(0, index=holdout_last_rows.index)\n",
        "\n",
        "utilization_high_persist_series = 0\n",
        "if \"utilization_high_persist_3m\" in holdout_last_rows.columns:\n",
        "    utilization_high_persist_series = holdout_last_rows[\"utilization_high_persist_3m\"]\n",
        "else:\n",
        "    print(\"Warning: 'utilization_high_persist_3m' not found in holdout_last_rows. Defaulting to 0 for LGD calculation.\")\n",
        "    utilization_high_persist_series = pd.Series(0, index=holdout_last_rows.index)\n",
        "\n",
        "#  LGD (Loss Given Default)\n",
        "lgd = (\n",
        "    0.35 +\n",
        "    0.1 * salary_delay_persist_series +\n",
        "    0.1 * utilization_high_persist_series\n",
        ")   # between 40% and 60%\n",
        "\n",
        "#  EXPECTED LOSS\n",
        "expected_loss = pd_scores * lgd * ead\n",
        "\n",
        "\n",
        "# CREATE RISK OUTPUT TABLE (SAFE ALIGNMENT)\n",
        "\n",
        "\n",
        "# Reset index to guarantee order alignment with predictions\n",
        "risk_output_df = holdout_last_rows.reset_index(drop=True).copy()\n",
        "\n",
        "# Add model outputs\n",
        "risk_output_df[\"PD\"] = pd_scores\n",
        "risk_output_df[\"LGD\"] = lgd.values\n",
        "risk_output_df[\"EAD\"] = ead.values\n",
        "\n",
        "risk_output_df[\"Expected_Loss\"] = (\n",
        "    risk_output_df[\"PD\"] *\n",
        "    risk_output_df[\"LGD\"] *\n",
        "    risk_output_df[\"EAD\"]\n",
        ")\n",
        "\n",
        "# Rank customers by Expected Loss\n",
        "risk_output_df = risk_output_df.sort_values(\n",
        "    \"Expected_Loss\", ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 5 Customers by Expected Loss:\")\n",
        "print(\n",
        "    risk_output_df[\n",
        "        [\"customer_id\",\"PD\",\"LGD\",\"EAD\",\"Expected_Loss\"]\n",
        "    ].head(10)\n",
        ")\n",
        "\n",
        "\n",
        "# Default Rate = 0.345\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q3yalaLtkWh",
        "outputId": "8c4c62ba-b72c-4ee8-fde4-ef74efe0e53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean PD: 0.34539782356543786\n",
            "Median PD: 0.19300079759484234\n",
            "Min PD: 0.05782311642903019\n",
            "Max PD: 0.8152599697705811\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean PD:\", risk_output_df[\"PD\"].mean())\n",
        "print(\"Median PD:\", risk_output_df[\"PD\"].median())\n",
        "print(\"Min PD:\", risk_output_df[\"PD\"].min())\n",
        "print(\"Max PD:\", risk_output_df[\"PD\"].max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "impg4mzytpLO",
        "outputId": "16b071ef-935b-4f6f-9130-9f5575318637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "risk_output_df[\"PD\"].hist(bins=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDiApiTRttgn",
        "outputId": "e8066b92-3621-43c0-ff1b-25324c4b8c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual default rate: 0.3453333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Actual default rate:\",\n",
        "      y_holdout_aligned.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7xPuO_ctxXk",
        "outputId": "63774a7e-c429-463d-b686-a70984d2157d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brier Score: 0.1530681736917101\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "print(\"Brier Score:\",\n",
        "      brier_score_loss(y_hybrid_actuals, calibrated_pd))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSUWNzAct0mM",
        "outputId": "3f744f11-bd0e-46ec-ca58-4eb5c01859d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PD_decile\n",
            "0    0.050661\n",
            "1    0.095238\n",
            "2    0.125000\n",
            "3    0.183888\n",
            "4    0.352941\n",
            "5    0.472067\n",
            "6    0.604730\n",
            "7    0.713568\n",
            "8    0.856187\n",
            "Name: loan_default_next_month, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "risk_output_df[\"PD_decile\"] = pd.qcut(\n",
        "    risk_output_df[\"PD\"], 10, labels=False, duplicates='drop'\n",
        ")\n",
        "\n",
        "decile_default_rate = (\n",
        "    risk_output_df\n",
        "    .groupby(\"PD_decile\")[\"loan_default_next_month\"]\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "print(decile_default_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYIylyNCwoCi"
      },
      "source": [
        "**SIMULATE REAL BANKING PORTFOLIO - 0.02% Default Rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rSq7NWXwm5J",
        "outputId": "ffc1acd8-efb7-44cd-c13f-1ebada8963df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Hybrid PD built using best weight.\n",
            "Old Mean PD: 0.34539782356543786\n",
            "Adjusted Mean PD: 0.01880721829596084\n",
            "\n",
            "Top 5 Customers by Expected Loss:\n",
            "   customer_id        PD   LGD            EAD  Expected_Loss\n",
            "0  CUST0013187  0.071185  0.55  604258.298917   23657.899430\n",
            "1  CUST0001491  0.080148  0.55  507474.605889   22370.277195\n",
            "2  CUST0003297  0.074589  0.55  520938.057576   21370.998869\n",
            "3  CUST0000499  0.076524  0.55  478112.199964   20122.841876\n",
            "4  CUST0010236  0.067358  0.55  516100.786868   19119.901702\n",
            "5  CUST0003643  0.074150  0.55  465855.564764   18998.707881\n",
            "6  CUST0012665  0.066605  0.55  494983.305500   18132.671633\n",
            "7  CUST0005620  0.070259  0.55  458226.908303   17706.998764\n",
            "8  CUST0003776  0.072702  0.55  432715.189117   17302.490034\n",
            "9  CUST0009862  0.075632  0.45  502282.849933   17094.887673\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# BUILD FINAL HYBRID PD USING BEST WEIGHT\n",
        "\n",
        "\n",
        "best_blended_preds = (\n",
        "    best_weight * tree_preds +\n",
        "    (1 - best_weight) * lstm_preds\n",
        ")\n",
        "\n",
        "print(\"\\nFinal Hybrid PD built using best weight.\")\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "calibrator = LogisticRegression()\n",
        "calibrator.fit(best_blended_preds.reshape(-1,1), y_hybrid_actuals)\n",
        "\n",
        "calibrated_pd = calibrator.predict_proba(\n",
        "    best_blended_preds.reshape(-1,1)\n",
        ")[:,1]\n",
        "\n",
        "# Production safety cap\n",
        "calibrated_pd = np.clip(calibrated_pd, 0.01, 0.95)\n",
        "\n",
        "\n",
        "# BASE RATE ADJUSTMENT TO 2% REALISTIC BANK\n",
        "\n",
        "\n",
        "real_world_default_rate = 0.02\n",
        "current_rate = y_hybrid_actuals.mean()\n",
        "\n",
        "p = calibrated_pd   # use calibrated PD\n",
        "\n",
        "adjusted_pd = (\n",
        "    p * real_world_default_rate\n",
        ") / (\n",
        "    p * real_world_default_rate +\n",
        "    (1 - p) * (1 - real_world_default_rate)\n",
        ")\n",
        "\n",
        "print(\"Old Mean PD:\", p.mean())\n",
        "print(\"Adjusted Mean PD:\", adjusted_pd.mean())\n",
        "\n",
        "\n",
        "\n",
        "# EXPECTED LOSS ENGINE (PD Ã— LGD Ã— EAD)\n",
        "\n",
        "\n",
        "# Get aligned holdout rows (same 3000 customers used in hybrid)\n",
        "holdout_last_rows = test_df_tree_global.groupby(\"customer_id\").tail(1)\n",
        "\n",
        "#  PD\n",
        "pd_scores = adjusted_pd  # (3000,)\n",
        "\n",
        "#  EAD (Exposure At Default)\n",
        "# Assume 6 months remaining EMI\n",
        "ead = (\n",
        "    holdout_last_rows[\"emi_amount\"] * 6 +\n",
        "    holdout_last_rows[\"credit_card_utilization\"] *\n",
        "    holdout_last_rows[\"monthly_income\"] * 2\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#  LGD (Loss Given Default)\n",
        "lgd = (\n",
        "    0.35 +\n",
        "    0.1 * holdout_last_rows[\"salary_delay_persist_3m\"] +\n",
        "    0.1 * holdout_last_rows[\"utilization_high_persist_3m\"]\n",
        ")   # between 40% and 60%\n",
        "\n",
        "#  EXPECTED LOSS\n",
        "expected_loss = pd_scores * lgd * ead\n",
        "\n",
        "\n",
        "# CREATE RISK OUTPUT TABLE (SAFE ALIGNMENT)\n",
        "\n",
        "\n",
        "# Reset index to guarantee order alignment with predictions\n",
        "risk_output_df = holdout_last_rows.reset_index(drop=True).copy()\n",
        "\n",
        "# Add model outputs\n",
        "risk_output_df[\"PD\"] = adjusted_pd\n",
        "risk_output_df[\"LGD\"] = lgd.values\n",
        "risk_output_df[\"EAD\"] = ead.values\n",
        "\n",
        "risk_output_df[\"Expected_Loss\"] = (\n",
        "    risk_output_df[\"PD\"] *\n",
        "    risk_output_df[\"LGD\"] *\n",
        "    risk_output_df[\"EAD\"]\n",
        ")\n",
        "\n",
        "# Rank customers by Expected Loss\n",
        "risk_output_df = risk_output_df.sort_values(\n",
        "    \"Expected_Loss\", ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop 5 Customers by Expected Loss:\")\n",
        "print(\n",
        "    risk_output_df[\n",
        "        [\"customer_id\",\"PD\",\"LGD\",\"EAD\",\"Expected_Loss\"]\n",
        "    ].head(10)\n",
        ")\n",
        "\n",
        "\n",
        "# Default Rate = 0.345\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10935e18",
        "outputId": "52880277-ef01-4d45-e9e5-4b9f8e8e98ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All hybrid model components saved successfully:\n",
            "- models/xgb_model.pkl\n",
            "- models/lgb_model.pkl\n",
            "- models/cat_model.cbm\n",
            "- models/lstm_model_state.pt\n",
            "- models/lstm_scaler.pkl\n",
            "- models/calibrator.pkl\n",
            "- models/tree_feature_columns.pkl\n",
            "- models/lstm_feature_columns.pkl\n",
            "- models/hybrid_config.json\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "# SAVE ALL HYBRID MODEL COMPONENTS\n",
        "\n",
        "\n",
        "# Create the models directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save tree-based models\n",
        "joblib.dump(xgb, 'models/xgb_model.pkl')\n",
        "joblib.dump(lgb, 'models/lgb_model.pkl')\n",
        "cat.save_model('models/cat_model.cbm')\n",
        "\n",
        "# Save LSTM model state dictionary and architecture\n",
        "torch.save(model.state_dict(), 'models/lstm_model_state.pt')\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, 'models/lstm_scaler.pkl')\n",
        "\n",
        "# Save calibrator\n",
        "joblib.dump(calibrator, 'models/calibrator.pkl')\n",
        "\n",
        "# Save tree feature columns\n",
        "joblib.dump(TREE_FEATURE_COLUMNS, 'models/tree_feature_columns.pkl')\n",
        "\n",
        "# Save LSTM feature columns\n",
        "joblib.dump(LSTM_FEATURE_COLS, 'models/lstm_feature_columns.pkl')\n",
        "\n",
        "# Save hybrid configuration\n",
        "hybrid_config = {\n",
        "    \"best_weight\": best_weight,\n",
        "    \"sequence_length\": SEQUENCE_LENGTH,\n",
        "    \"hidden_size\": HIDDEN_SIZE\n",
        "}\n",
        "with open('models/hybrid_config.json', 'w') as f:\n",
        "    json.dump(hybrid_config, f, indent=4)\n",
        "\n",
        "print(\"All hybrid model components saved successfully:\")\n",
        "print(\"- models/xgb_model.pkl\")\n",
        "print(\"- models/lgb_model.pkl\")\n",
        "print(\"- models/cat_model.cbm\")\n",
        "print(\"- models/lstm_model_state.pt\")\n",
        "print(\"- models/lstm_scaler.pkl\")\n",
        "print(\"- models/calibrator.pkl\")\n",
        "print(\"- models/tree_feature_columns.pkl\")\n",
        "print(\"- models/lstm_feature_columns.pkl\")\n",
        "print(\"- models/hybrid_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceu0D7vCA0M_",
        "outputId": "08a5db95-605c-4574-bf35-48c041818ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: content/ (stored 0%)\n",
            "updating: content/.config/ (stored 0%)\n",
            "updating: content/.config/gce (stored 0%)\n",
            "updating: content/.config/default_configs.db (deflated 98%)\n",
            "updating: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "updating: content/.config/configurations/ (stored 0%)\n",
            "updating: content/.config/configurations/config_default (deflated 15%)\n",
            "updating: content/.config/.last_update_check.json (deflated 22%)\n",
            "updating: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "updating: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "updating: content/.config/active_config (stored 0%)\n",
            "updating: content/.config/logs/ (stored 0%)\n",
            "updating: content/.config/logs/2026.01.16/ (stored 0%)\n",
            "updating: content/.config/logs/2026.01.16/14.24.18.954466.log (deflated 58%)\n",
            "updating: content/.config/logs/2026.01.16/14.23.31.981136.log (deflated 92%)\n",
            "updating: content/.config/logs/2026.01.16/14.24.29.392089.log (deflated 56%)\n",
            "updating: content/.config/logs/2026.01.16/14.24.13.071214.log (deflated 87%)\n",
            "updating: content/.config/logs/2026.01.16/14.24.03.314209.log (deflated 58%)\n",
            "updating: content/.config/logs/2026.01.16/14.24.28.646070.log (deflated 57%)\n",
            "updating: content/.config/config_sentinel (stored 0%)\n",
            "updating: content/catboost_info/ (stored 0%)\n",
            "updating: content/catboost_info/time_left.tsv (deflated 49%)\n",
            "updating: content/catboost_info/learn/ (stored 0%)\n",
            "updating: content/catboost_info/learn/events.out.tfevents (deflated 78%)\n",
            "updating: content/catboost_info/tmp/ (stored 0%)\n",
            "updating: content/catboost_info/learn_error.tsv (deflated 56%)\n",
            "updating: content/catboost_info/catboost_training.json (deflated 75%)\n",
            "updating: content/financial_stress_full_bank_grade_dataset.csv (deflated 77%)\n",
            "updating: content/models/ (stored 0%)\n",
            "updating: content/models/cat_model.cbm (deflated 41%)\n",
            "updating: content/models/lgb_model.txt (deflated 58%)\n",
            "updating: content/models/feature_columns.pkl (deflated 74%)\n",
            "updating: content/models/xgb_model.json (deflated 83%)\n",
            "updating: content/models/calibrator.pkl (deflated 36%)\n",
            "updating: content/models/lstm_scaler.pkl (deflated 15%)\n",
            "updating: content/models/lstm_model_state.pt (deflated 9%)\n",
            "updating: content/models/lstm_model.pt (deflated 9%)\n",
            "updating: content/models/hybrid_config.json (deflated 15%)\n",
            "updating: content/sample_data/ (stored 0%)\n",
            "updating: content/sample_data/anscombe.json (deflated 83%)\n",
            "updating: content/sample_data/README.md (deflated 39%)\n",
            "updating: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "updating: content/sample_data/california_housing_train.csv (deflated 79%)\n",
            "updating: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "updating: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/models/lstm_feature_columns.pkl (deflated 36%)\n",
            "  adding: content/models/lgb_model.pkl (deflated 58%)\n",
            "  adding: content/models/tree_feature_columns.pkl (deflated 74%)\n",
            "  adding: content/models/xgb_model.pkl (deflated 83%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r content_backup.zip /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NlsGz4v5EaIq",
        "outputId": "f3ca46eb-2ffe-41ea-9788-dd6bf4800bb6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_80f061e1-bf26-4198-b6da-34cf86e3cd4f\", \"content_backup.zip\", 12938141)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"content_backup.zip\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikk4o6wDSvIV",
        "outputId": "0ebcdc26-1f34-419e-faf0-b868490c1419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 74\n",
            "['active_products_count', 'credit_card_utilization', 'total_monthly_obligation', 'emi_amount', 'days_to_emi', 'emi_to_income_ratio', 'salary_delay_days', 'weekly_balance_change_pct', 'atm_withdrawal_amount', 'monthly_income', 'risk_level_latent', 'active_products_count_lag1', 'active_products_count_lag2', 'credit_card_utilization_lag1', 'credit_card_utilization_lag2', 'total_monthly_obligation_lag1', 'total_monthly_obligation_lag2', 'emi_amount_lag1', 'emi_amount_lag2', 'days_to_emi_lag1', 'days_to_emi_lag2', 'emi_to_income_ratio_lag1', 'emi_to_income_ratio_lag2', 'salary_delay_days_lag1', 'salary_delay_days_lag2', 'weekly_balance_change_pct_lag1', 'weekly_balance_change_pct_lag2', 'atm_withdrawal_amount_lag1', 'atm_withdrawal_amount_lag2', 'monthly_income_lag1', 'monthly_income_lag2', 'active_products_count_delta_1', 'active_products_count_delta_2', 'credit_card_utilization_delta_1', 'credit_card_utilization_delta_2', 'total_monthly_obligation_delta_1', 'total_monthly_obligation_delta_2', 'emi_amount_delta_1', 'emi_amount_delta_2', 'days_to_emi_delta_1', 'days_to_emi_delta_2', 'emi_to_income_ratio_delta_1', 'emi_to_income_ratio_delta_2', 'salary_delay_days_delta_1', 'salary_delay_days_delta_2', 'weekly_balance_change_pct_delta_1', 'weekly_balance_change_pct_delta_2', 'atm_withdrawal_amount_delta_1', 'atm_withdrawal_amount_delta_2', 'monthly_income_delta_1', 'monthly_income_delta_2', 'credit_card_utilization_std_3m', 'weekly_balance_change_pct_std_3m', 'monthly_income_std_3m', 'credit_card_utilization_mean_3m', 'credit_card_utilization_max_3m', 'credit_card_utilization_slope_3m', 'monthly_income_mean_3m', 'monthly_income_max_3m', 'monthly_income_slope_3m', 'emi_to_income_ratio_mean_3m', 'emi_to_income_ratio_max_3m', 'emi_to_income_ratio_slope_3m', 'weekly_balance_change_pct_mean_3m', 'weekly_balance_change_pct_max_3m', 'weekly_balance_change_pct_slope_3m', 'emi_high_persist_3m', 'salary_delay_persist_3m', 'utilization_high_persist_3m', 'customer_segment_self_employed', 'region_tier_tier_2', 'region_tier_tier_3', 'product_type_credit_card', 'product_type_personal_loan']\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "tree_feature_cols = joblib.load(\"models/tree_feature_columns.pkl\")\n",
        "\n",
        "print(\"Number of features:\", len(tree_feature_cols))\n",
        "print(tree_feature_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWVMITJAfyww",
        "outputId": "4b7cf57f-b7ee-4401-a8f5-253fbcbf8a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 15\n",
            "['active_products_count', 'credit_card_utilization', 'total_monthly_obligation', 'emi_amount', 'days_to_emi', 'emi_to_income_ratio', 'salary_delay_days', 'weekly_balance_change_pct', 'atm_withdrawal_amount', 'monthly_income', 'customer_segment_self_employed', 'region_tier_tier_2', 'region_tier_tier_3', 'product_type_credit_card', 'product_type_personal_loan']\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "lstm_feature_cols = joblib.load(\"models/lstm_feature_columns.pkl\")\n",
        "\n",
        "print(\"Number of features:\", len(lstm_feature_cols))\n",
        "print(lstm_feature_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNI-enCWWGBh",
        "outputId": "376772c9-c97f-4951-b201-efb71497c458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM input size: 15\n",
            "Feature count: 15\n",
            "['active_products_count', 'credit_card_utilization', 'total_monthly_obligation', 'emi_amount', 'days_to_emi', 'emi_to_income_ratio', 'salary_delay_days', 'weekly_balance_change_pct', 'atm_withdrawal_amount', 'monthly_income', 'customer_segment_self_employed', 'region_tier_tier_2', 'region_tier_tier_3', 'product_type_credit_card', 'product_type_personal_loan']\n"
          ]
        }
      ],
      "source": [
        "print(\"LSTM input size:\", model.lstm.input_size)\n",
        "print(\"Feature count:\", len(LSTM_FEATURE_COLS))\n",
        "print(LSTM_FEATURE_COLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZKiDt96fABL",
        "outputId": "ae700505-a46f-433a-e22c-8c7f465d1280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature count: 74\n",
            "['active_products_count', 'credit_card_utilization', 'total_monthly_obligation', 'emi_amount', 'days_to_emi', 'emi_to_income_ratio', 'salary_delay_days', 'weekly_balance_change_pct', 'atm_withdrawal_amount', 'monthly_income', 'risk_level_latent', 'active_products_count_lag1', 'active_products_count_lag2', 'credit_card_utilization_lag1', 'credit_card_utilization_lag2', 'total_monthly_obligation_lag1', 'total_monthly_obligation_lag2', 'emi_amount_lag1', 'emi_amount_lag2', 'days_to_emi_lag1', 'days_to_emi_lag2', 'emi_to_income_ratio_lag1', 'emi_to_income_ratio_lag2', 'salary_delay_days_lag1', 'salary_delay_days_lag2', 'weekly_balance_change_pct_lag1', 'weekly_balance_change_pct_lag2', 'atm_withdrawal_amount_lag1', 'atm_withdrawal_amount_lag2', 'monthly_income_lag1', 'monthly_income_lag2', 'active_products_count_delta_1', 'active_products_count_delta_2', 'credit_card_utilization_delta_1', 'credit_card_utilization_delta_2', 'total_monthly_obligation_delta_1', 'total_monthly_obligation_delta_2', 'emi_amount_delta_1', 'emi_amount_delta_2', 'days_to_emi_delta_1', 'days_to_emi_delta_2', 'emi_to_income_ratio_delta_1', 'emi_to_income_ratio_delta_2', 'salary_delay_days_delta_1', 'salary_delay_days_delta_2', 'weekly_balance_change_pct_delta_1', 'weekly_balance_change_pct_delta_2', 'atm_withdrawal_amount_delta_1', 'atm_withdrawal_amount_delta_2', 'monthly_income_delta_1', 'monthly_income_delta_2', 'credit_card_utilization_std_3m', 'weekly_balance_change_pct_std_3m', 'monthly_income_std_3m', 'credit_card_utilization_mean_3m', 'credit_card_utilization_max_3m', 'credit_card_utilization_slope_3m', 'monthly_income_mean_3m', 'monthly_income_max_3m', 'monthly_income_slope_3m', 'emi_to_income_ratio_mean_3m', 'emi_to_income_ratio_max_3m', 'emi_to_income_ratio_slope_3m', 'weekly_balance_change_pct_mean_3m', 'weekly_balance_change_pct_max_3m', 'weekly_balance_change_pct_slope_3m', 'emi_high_persist_3m', 'salary_delay_persist_3m', 'utilization_high_persist_3m', 'customer_segment_self_employed', 'region_tier_tier_2', 'region_tier_tier_3', 'product_type_credit_card', 'product_type_personal_loan']\n"
          ]
        }
      ],
      "source": [
        "print(\"Feature count:\", len(TREE_FEATURE_COLUMNS))\n",
        "print(TREE_FEATURE_COLUMNS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
